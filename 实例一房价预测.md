---
title: 房价预测
date: 2018-10-04 18:28:04
tags:
categories: 实战
---

这是之9.20前做的两份的总结，只敲过Slearn上的，等之后再归纳一次升级版~<br>
10.4更-----------[阿帕奇课程笔记](https://github.com/Cooper111/Keras_And_Scikt-learn_Practice/blob/master/Housing_Based_on_github.ipynb)

# 房价预测

### 数据导入&&初步处理与观测
#### 注
##### Keras数据为现成的
- 不用观测，也不用清洗，只做标准化就行

##### Scikt-Learn数据是一个csv
- 不去动测试集而划分，观测，清洗

##### Kaggle（1）数据是train.csv,test.csv
- 想观测并一起处理而合并再观测,清洗&&处理，划分

#### Keras书上
- from keras.datasets import boston_housing 导入
- boston_housing.load_data() 加载
- numpy.array().shape 观测形状

#### Scikt-Learn书上
- pd.read_csv("housing.csv")#单个文件
- DataFrame的Head()查看前五行
- DataFrame的Describe()显示属性摘要
- DataFrame的对文本属性Value_counts
- DataFrame的Hist()观测各个属性
- 划分训练集和测试集，四种方法见前

#### Kaggle（1）上的
- pd.read_csv()读取训练集和测试集
- DataFrame.dtypes.value_counts()查看各列数据类型
- 合并'MSSubClass':'SaleCondition'之间所有属性,concat的axis=0就是保持数据每条的独立
- 发现数据MSSubClass应为字符类型，进行转换


### 数据观测
#### Keras
<pre>
train_data.shape#(404, 13)
test_data.shape#(102, 13)
train_targets.shape#(404,)
</pre>

#### Scikt_learn书上
- 地理：绘图将地理信息可视化，地理分布突出高密度
- 地理：绘图观测房价，每个圆半径代表每个地区的人口数量（s），颜色代表价格（c），使用jet的预定义颜色表（cmap）
- 地理：加载加利福尼亚州地理图，使用自定义的colobar，设置分层和坐标刻度
- 寻找相关性1：使用DataFrame的correct()计算出每对属性之间的标准相关系数（皮尔逊系数
- 寻找相关性1：查看和房价中位数相关系数
- 寻找相关性2：使用scatter_matrix()画出每个属性对于各属性的非线性相关性
- 寻找相关性3：验证不同属性的组合，创造新属性，在按上述寻找相关性

#### Kaggle（1）上
- 相关性：查看训练集的相关性矩阵，如果值高说明相关性高，存在共线性，只保留共性特征中的1个
<pre>
corrmat = df_train.corr()
f, ax = plt.subplots(figsize=(20, 10))
sns.heatmap(corrmat, vmax=.8, square=True)
</pre>
- 相关性：查看系数矩阵和Y值最相关的10个特征
- 相关性：将10个特征相关系统矩阵按图形展示
- 相关性：删除共线性特征，保留与y值相关性高的特征
>DataFrame.drop('name', axis=1)
- 相关性后续：见清洗&&处理


### 数据清洗&&处理

#### Keras书上
<pre>#标准化
mean = train_data.mean(axis=0)
train_data -= mean
std = train_data.std(axis=0)
train_data /= std

test_data -= mean
test_data /= std
</pre>

#### Scikt_learn书上
- 处理缺失值1： 对数值使用SimpleImputer处理缺失值
- 处理缺失值1： 对数值增加三新自制属性
- 处理缺失值1： 对数值特征缩放，标准化
- 处理缺失值2： 对文本使用OneHotEncoder()，直接文本转独热向量
- 处理缺失值3：使用Pipeline

#### Kaggle（1）上
- 处理缺失值：统计展示缺失数据情况
- 处理缺失值：图形展示缺失数据
- 处理缺失值：同时是相关性列，也是缺失数据的有2个
- 处理缺失值：查看这2个特征的缺失情况
- 处理缺失值：drop掉其它缺失数据列
- 处理缺失值：对于剩余的数据按列平均值进行填充
- 余一个特殊为字符的后续转化成one_hot处理
- 将字符值特征转换成one_hot类型
- 相关性：查看所有特殊的相关系数矩阵，对于值超过0.8的只取其中1个
- 划分：把数据集拆分成训练集和测试集
- 观测训练集，处理异常1：查看训练集的数据情况
- 观测训练集，处理异常1：单独查看特征和y值情况
- 观测训练集，处理异常1：查看右下2个异常点
- 观测训练集，处理异常1：drop这2个异常点
- 观测训练集，处理异常2：查看y值的分布情况，图形显示正偏度
- 观测训练集，处理异常2：取对数处理正偏度情况
>y = np.log(y)
- 拆分训练集和验证集

### 模型构建
#### Keras书上
<pre>
#函数式编程返回编译好的模型
from keras import models
from keras import layers

def build_model():
​    # Because we will need to instantiate
​    # the same model multiple times,
​    # we use a function to construct it.
​    model = models.Sequential()
​    model.add(layers.Dense(64, activation='relu',
​                           input_shape=(train_data.shape[1],)))
​    model.add(layers.Dense(64, activation='relu'))
​    model.add(layers.Dense(1))
​    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])#均方差
​    return model
</pre>
#### Scikt_learn书上
- SVR
<pre>
from sklearn.svm import SVR

svm_reg = SVR(kernel="linear")
svm_reg.fit(housing_prepared, housing_labels)
housing_predictions = svm_reg.predict(housing_prepared)
</pre>

- 随机森林
<pre>
from sklearn.ensemble import RandomForestRegressor

forest_reg = RandomForestRegressor(random_state=42)
forest_reg.fit(housing_prepared, housing_labels)
</pre>

- 线性模型
<pre>
from sklearn.linear_model import LinearRegression
# Select a linear model
model = sklearn.linear_model.LinearRegression()
# model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)

# Train the model
model.fit(X, y)

# Make a prediction for Cyprus
X_new = [[22587]]  # Cyprus' GDP per capita
print(model.predict(X_new)) # outputs [[ 5.96242338]]
</pre>

- KNN回归
<pre>
model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

# Train the model
model.fit(X, y)

# Make a prediction for Cyprus
X_new = np.array([[22587.0]])  # Cyprus' GDP per capita
print(model.predict(X_new)) 
# outputs [[ 5.76666667]]
# =======================用同一集训练和验证，差==============================
</pre>
- 决策树回归
<pre>
from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor(random_state=42)
tree_reg.fit(housing_prepared, housing_labels)
print("Housing_Prepared: ", tree_reg.predict(housing_prepared))
</pre>


#### Kaggle（1）上
<pre>
# 使用线性回归进行拟合，使用验证集进行评估
from sklearn import linear_model
lr = linear_model.LinearRegression()
model = lr.fit(X_train, y_train)
pred = model.predict(X_test)


</pre>

### 模型评估与优化

#### Keras
<pre>
- Kn折交叉验证
- 画图
- 模型优化，轮次更新
- 使用测试集
</pre>

#### Scikt-Learn书上
##### 查看每个超参数组合得分
- 网格搜索GridSearchCV
- 随机搜索RandomizedSearchCV

##### 分析最佳模型及其错误
>有了这些信息，你可以尝试删除一些不太有用的特征
##### 使用测试集评估

#### Kagggle（1）上
<pre>
from sklearn.metrics import mean_squared_error
print('RMSE is: \n', mean_squared_error(y_test, pred))
# 预测测试集数据，生成结果
test_pred = model.predict(test)
test_pred = np.exp(test_pred)

output = pd.DataFrame({'Id': df_test['Id'], 'SalePrice': test_pred})
output.to_csv('output.csv', index=False)
</pre>
### 参考资料：
- [Kaggle里房价预测集锦](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/kernels)

- [Kaggle里房价预测精选](https://www.kaggle.com/apapiu/regularized-linear-models)

- [简书教程](https://www.jianshu.com/p/93feb3f625a8)
- Python深度学习-第三章-Boston房价预测
- Hands-On Marchine Learning with Scikt-Learn && Tensorflow—第二章
- [DataFrame.loc使用](https://blog.csdn.net/qq1483661204/article/details/77587881)

